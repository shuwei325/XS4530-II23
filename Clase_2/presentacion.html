<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tema 2.3. Series de tiempo para pronóstico</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Shu Wei Chou Chen" />
    <script src="presentacion_files/header-attrs/header-attrs.js"></script>
    <link href="presentacion_files/remark-css/default.css" rel="stylesheet" />
    <link href="presentacion_files/remark-css/metropolis.css" rel="stylesheet" />
    <link href="presentacion_files/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="presentacion_files/remark-css/ninjutsu.css" rel="stylesheet" />
    <link rel="stylesheet" href="text_color.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Tema 2.3. Series de tiempo para pronóstico
]
.subtitle[
## Curso: Decisiones Estadísticas y Administrativas
]
.author[
### Prof. Shu Wei Chou Chen
]
.institute[
### Escuela de Estadística, UCR
]

---







# Subtemas

1. Series de tiempo y pronóstico
2. Descomposición de series temporales
3. **Técnicas de suavizamiento exponencial**
4. **Regresión aplicada a series cronológicas**


---
# Contenido

1. Introducción
2. Suavizamiento exponencial simple
3. Método lineal de Holt
4. Métodos multiplicativo y aditivo de Holt-Winters


---
# Introducción

- Desarrollados en los años 1950s.
- Son aplicados ampliamente debido a su sencillez y bajo costo.
- Pueden ser utilizados para pocas observaciones.

1. Suavizamiento exponencial simple (SES)
2. Método lineal de Holt (con tendencia)
3. Métodos multiplicativo y aditivo de Holt-Winters (con estacionalidad)

---
# Suavizamiento exponencial simple (SES)

- Es apropiada para serie que no tienen patrones estacionales ni de tendencia, y cuya la media o nivel cambia lentamente.

- Notación:
  - `\(Z_t\)`: la observación de la serie en el tiempo `\(t\)`.
  - `\(P_t\)`: el pronóstico del tiempo `\(t\)`.
  - `\(Z_t-P_t\)`: el error de pronóstico.

- El método de SES consiste en:
`$$P_{t+1}=P_t+\alpha (Z_t-P_t)$$`
donde `\(0&lt;\alpha&lt;1\)` es el parámetro de suavizamiento.&lt;br /&gt;
i.e., el pronóstico en el tiempo `\(t+1\)` es una combinación del pronóstico en el tiempo `\(t\)` y una proporción `\(\alpha\)` el error de pronóstico del tiempo `\(t\)`.


---
# Suavizamiento exponencial simple (SES)

- Note que la ecuación anterior es equivalente a:
`$$P_{t+1}=\alpha Z_t + (1-\alpha)~ P_t$$`
i.e., el pronóstico en el tiempo `\(t+1\)` es un promedio ponderado de la observación más reciente y el pronóstico en el tiempo `\(t\)`.

- Recursivamente se obtienen:

`$$P_{t+1}=\alpha Z_t + (1-\alpha) \left[ \alpha Z_{t-1} + (1-\alpha) P_{t-1} \right]$$`
`$$=\alpha Z_t + \alpha (1-\alpha) Z_{t-1} + (1-\alpha)^2 P_{t-1}$$`
`$$=\alpha Z_t + \alpha (1-\alpha) Z_{t-1}+\alpha (1-\alpha)^2 Z_{t-2}+... + \alpha (1-\alpha)^{t-1} Z_1 + (1-\alpha)^t P_{1}$$`
- Los coeficientes `\(\alpha, \alpha (1-\alpha)^2,..., \alpha (1-\alpha)^t\)` decrecen exponencialmente.
- El pronóstico `\(P_{t+1}\)` es un promedio ponderado de las observaciones pasadas `\(Z_t,...,Z_1\)` ya que  `\((1-\alpha)^t P_{1}\)` es casi nulo.

---
# Suavizamiento exponencial simple (SES)

- La idea es realizar SES con diferentes valores de `\(\alpha\)` y seleccionar el valor de `\(\alpha\)` que minimiza la suma de los cuadrados de los errores de pronóstico, o el MSE.
$$MSE=\frac{\sum\limits_{t=1}^T \left( Z_t-P_t \right)^2}{T} $$

---
# Suavizamiento exponencial simple (SES)

- Ejemplo 3.1 de Hernández (2011): Serie mensual de defunciones de Costa Rica de los años 2001 y 2002.

&lt;img src="presentacion_files/figure-html/unnamed-chunk-2-1.png" width="35%" style="display: block; margin: auto;" /&gt;

- Vamos al excel y el laboratorio.

- Consideraciones importantes.
  - Selección de los valores iniciales.




---
# El método lineal de Holt

- El método de Holt sirve para series con tendencia.
- El suavizamiento exponencial de Holt utiliza 3 ecuaciones y dos parámetros ( `\(\alpha\)` y `\(\beta\)` ):

Ecuación del nivel: `\(~~~~~~~~~~~~~l_{t}=\alpha Z_{t} + (1-\alpha)~ (l_{t-1}+b_{t-1})\)`

Ecuación de la pendiente: `\(~~~~b_{t}=\beta (l_t-l_{t-1}) + (1-\beta)~ b_{t-1}\)`

Ecuación del pronóstico: `\(~~~~~P_{t+m}=l_t+b_t m\)`
- `\(l_t\)` es una estimación del nivel promedio de `\(Z_t\)`
  - es un promedio ponderado del valor de `\(Z_t\)` y una estimación del nivel de la serie en `\(t\)`.
- `\(b_t\)` es una estimación de la pendiente de `\(Z_t\)`.
  - es un promedio ponderado del aumento del nivel de la serie entre `\(t\)` y `\(t-1\)`, y una estimación de la pendiente en el tiempo `\(t-1\)`.
- La última ecuación pronostica el valor de `\(Z_{t+m}\)`, i.e., pronóstico a `\(m\)` paso para adelante.

- Es conocido como **suavizamiento exponencial doble**.

---
# El método lineal de Holt

- Al igual que SES, los valores de `\(\alpha\)` y `\(\beta\)` se obtienen minimizando la suma de los cuadrados de los errores de pronóstico, o el MSE.
$$MSE=\frac{\sum\limits_{i=1}^T \left( Z_t-P_t \right)^2}{T} $$

- Ejemplo 3.2 de Hernández (2011): Serie de graduados del ITCR de 1975-2002.

&lt;img src="presentacion_files/figure-html/unnamed-chunk-3-1.png" width="35%" style="display: block; margin: auto;" /&gt;

---
# El método multiplicativo y aditivo de Holt-Winters

- [Winters (1960)](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324) extendió el método lineal de Holt para tomar en cuenta la estacionalidad, el cual es conocido como Holt-Winters.

1. Método multiplicativo
  - Variación estacional cambia proporcionalmente con el nivel de la serie.

2. Método aditivo
  - Variación constante a lo largo de tiempo.

---
# El método multiplicativo de Holt-Winters


`$$l_t= \alpha \frac{Z_t}{S_{t-s}}+(1-\alpha) (l_{t-1}+b_{t-1})$$`
`$$b_t= \beta (l_t-l_{t-1})+(1-\beta) b_{t-1}$$`
`$$S_t= \gamma \frac{Z_t}{l_{t-1}+b_{t-1}}+(1-\gamma) S_{t-s}$$`
`$$P_{t+m}= (l_{t}+b_t~m) S_{t+m-s}$$`
donde &lt;br /&gt; 
`\(s\)` es la longitud de la estacionalidad, &lt;br /&gt; `\(l_t\)` es el nivel de la serie `\(Z_t\)`, &lt;br /&gt; `\(b_t\)` es la tendencia, &lt;br /&gt; `\(S_t\)` es el componente estacional, &lt;br /&gt; `\(P_{t+m}\)` es el pronóstico `\(m\)` pasos adelante y &lt;br /&gt; `\(0&lt;\alpha&lt;1\)`, `\(0&lt;\beta&lt;1\)`, `\(0&lt;\gamma&lt;1\)`.

---
# El método multiplicativo de Holt-Winters

**Valores iniciales:** para `\(s\)` periodos,&lt;br /&gt;
- El nivel `\(l_t\)` se inicia con:
`$$l_s=\frac{Z_1+...+Z_s}{s}$$`
como un promedio de los datos de los primeros `\(s\)` datos.

- La pendiente `\(b_t\)` se inicia con:
`$$b_s=\frac{1}{s}\left[ \frac{Z_{s+1}-Z_1}{s}+\frac{Z_{s+2}-Z_2}{s}+...+\frac{Z_{s+s}-Z_s}{s}   \right]$$`
`$$=\frac{1}{s}\left[ \frac{Z_{s+1}+...+Z_{s+s}}{s}-\frac{Z_{1}+...+Z_{s}}{s} \right]$$`
como un promedio de pendientes de cada periodo en los primeros `\(2s\)` periodos.

---
# El método multiplicativo de Holt-Winters

- Los índices estacionales se inicializan como cociente de los primeros `\(s\)` valores al promedio de los primeros `\(s\)` datos.
`$$S_i=\frac{Z_i}{l_s}, \text{ para } i=1,...,s$$`

- Ejemplo 3.3 de Hernández (2011): Serie mensual de turistas de 1991-2000.

&lt;img src="presentacion_files/figure-html/unnamed-chunk-4-1.png" width="35%" style="display: block; margin: auto;" /&gt;


---
# El método multiplicativo de Holt-Winters

&lt;img src="presentacion_files/figure-html/unnamed-chunk-5-1.png" width="600px" height="400px" style="display: block; margin: auto;" /&gt;


---
# El método aditivo de Holt-Winters


`$$l_t= \alpha (Z_t-S_{t-s})+(1-\alpha) (l_{t-1}+b_{t-1})$$`
`$$b_t= \beta (l_t-l_{t-1})+(1-\beta) b_{t-1}$$`
`$$S_t= \gamma \left( Z_t-l_{t-1}-b_{t-1} \right)+(1-\gamma) S_{t-s}$$`
`$$P_{t+m}= l_{t}+b_t~m + S_{t+m-s}$$`
donde &lt;br /&gt; 
`\(s\)` es la longitud de la estacionalidad, &lt;br /&gt; `\(l_t\)` es el nivel de la serie `\(Z_t\)`, &lt;br /&gt; `\(b_t\)` es la tendencia, &lt;br /&gt; `\(S_t\)` es el componente estacional, &lt;br /&gt; `\(P_{t+m}\)` es el pronóstico `\(m\)` pasos adelante y &lt;br /&gt; `\(0&lt;\alpha&lt;1\)`, `\(0&lt;\beta&lt;1\)`, `\(0&lt;\gamma&lt;1\)`.

---
# El método aditivo de Holt-Winters

- Los índices estacionales se inicializan como cociente de los primeros `\(s\)` valores al promedio de los primeros `\(s\)` datos.
`$$S_i=Z_i-a_s, \text{ para } i=1,...,s$$`

- Existen otras inicializaciones como el procedimiento basado en regresión (Bowerman, O’Connell and Koehler, 2005).
  - asumir tendencia lineal de las primeras observaciones (típicamente 3 o 4 años), y usa el intercepto como `\(l_0\)` y pendiente como `\(b_0\)`.
- Hasta los últimos años siguen proponiendo nuevos métodos.


---
# El método aditivo y mult. de Holt-Winters


&lt;img src="presentacion_files/figure-html/unnamed-chunk-6-1.png" width="500px" height="300px" style="display: block; margin: auto;" /&gt;


RMSE del método multiplicativo: 3239.92.  
RMSE del método aditivo: 4297.824.   

---
# Regresión aplicada a series cronológicas

- La idea es ajustar un modelo de regresión para la serie temporal `\(Y_t, t=1,...,T\)` utlizando un conjunto de `\(p\)` covariables: `\(X_1,...,X_p\)`.

- Por ejemplo: 
  - `\(Y\)` una serie mensual de ventas con la variable independiente `\(X_1\)` gasto mensual en anuncios.
  - `\(Y\)` una serie diaria de demanda de energía eléctrica con las variables independientes: `\(X_1\)` temperatura y `\(X_2\)` el día de la semana.


---
# Regresión lineal múltiple

- La forma general de un modelo de regresión lineal múltiple es:

`$$Y_t=\beta_0+\beta_1 X_{t,1}+\beta_2 X_{t,2}+...+\beta_p X_{t,p}+\epsilon_t, t=1,...,T,$$` 

donde `\(Y_t\)` es la variable a pronosticar y `\(X_1,...,X_p\)` son los `\(p\)` variables predictoras. Las variables predictoras pueden ser numéricas o categóricas (con el manejo apropiado de factores).   
Los coeficientes `\(\beta_1,...,\beta_p\)` miden el efecto de cada predictor después de tener en cuenta los efectos de todos los demás predictores del modelo. Por lo tanto, los coeficientes miden los efectos marginales de las variables predictoras.


---
# Regresión lineal múltiple

- El modelo de regresión lineal múltiple en su forma matricial:

$$
Y=X \beta+\epsilon
$$
donde

`$$Y=\left[ \begin{array}{c}Y_1 \\ \vdots \\Y_T \end{array}  \right],~~ X= \left(\begin{array}{ccccc} 1&amp; X_{11}&amp; X_{12} &amp; ... &amp; X_{1p}\\ 1 &amp;  X_{21}&amp; X_{22} &amp; ... &amp;X_{2p}\\ \vdots&amp; \vdots &amp; \ddots &amp;\vdots&amp; \vdots\\ 1&amp;  X_{T1}&amp; X_{T2} &amp; ... &amp;X_{Tp} \end{array}\right),$$`
`$$\beta=\left[ \begin{array}{c}\beta_0 \\ \vdots \\\beta_T \end{array}  \right],~~\epsilon=\left[ \begin{array}{c}\epsilon_1 \\ \vdots \\\epsilon_T \end{array}  \right].$$` 

---
# Regresión lineal múltiple


**Supocisiones del modelo:**

- La relación entre la variable de pronóstico y las variables predictoras satisface esta ecuación lineal.

- Los errores `\(\varepsilon_1,...,\varepsilon_T\)`:
  - tienen media cero,
  - no están autocorrelacionados,
  - no están relacionados con las variables predictoras

- Los errores se distribuyan normalmente con una varianza constante `\(\sigma^2\)`.

- Cada predictor `\(X_i, i=1,...,p\)` supone que es observado y fijo, i.e. no es una variable aleatoria.

---
# Regresión lineal múltiple

**Tópicos importantes:**

1. Estimación:
  - por mínimos cuadrados.
  - por máxima verosimilitud.
  
2. Selección de variables

3. Diagnósticos

4. Medidas remediales

---
# Regresión lineal múltiple: Ejemplo 

Se tienen datos de variaciones porcentuales trimestrales (tasas de crecimiento) del consumo personal real (Y), ingresos, producción industrial, ahorros personales y tasa de desempleo, para EE.UU. desde 1970 a 2016.


&lt;img src="presentacion_files/figure-html/MultiPredictors-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---
# Regresión lineal múltiple: Ejemplo

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="presentacion_files/figure-html/ScatterMatrix-1.png" alt="Matriz de diagrama de dispersión del gasto de consumo de EE. UU. y los cuatro predictores." width="50%" /&gt;
&lt;p class="caption"&gt;Matriz de diagrama de dispersión del gasto de consumo de EE. UU. y los cuatro predictores.&lt;/p&gt;
&lt;/div&gt;


---
# Regresión lineal múltiple: Ejemplo


```
## 
## Call:
## tslm(formula = Consumption ~ Income + Production + Unemployment + 
##     Savings, data = uschange)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.88296 -0.17638 -0.03679  0.15251  1.20553 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   0.26729    0.03721   7.184 1.68e-11 ***
## Income        0.71449    0.04219  16.934  &lt; 2e-16 ***
## Production    0.04589    0.02588   1.773   0.0778 .  
## Unemployment -0.20477    0.10550  -1.941   0.0538 .  
## Savings      -0.04527    0.00278 -16.287  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3286 on 182 degrees of freedom
## Multiple R-squared:  0.754,	Adjusted R-squared:  0.7486 
## F-statistic: 139.5 on 4 and 182 DF,  p-value: &lt; 2.2e-16
```


---
# Regresión lineal múltiple: Ejemplo

&lt;img src="presentacion_files/figure-html/unnamed-chunk-7-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---
# Regresión lineal múltiple: Ejemplo

&lt;img src="presentacion_files/figure-html/unnamed-chunk-8-1.png" width="50%" style="display: block; margin: auto;" /&gt;

```
## 
## 	Breusch-Godfrey test for serial correlation of order up to 8
## 
## data:  Residuals from Linear regression model
## LM test = 14.874, df = 8, p-value = 0.06163
```


---
# Regresión espuria

- Cuando las series no son estacionarias, los resultados de regresión no son confiables y presenta lo que se llama correlación espuria.

- Los datos de las series cronológicas de tendencias pueden parecer relacionados.
- Por ejemplo, los pasajeros aéreos en Australia tienen una correlación positiva con la producción de arroz en Guinea.

&lt;img src="presentacion_files/figure-html/spurious-1.png" width="350px" height="250px" style="display: block; margin: auto;" /&gt;

---
# Regresión espuria


```
## 
## Call:
## tslm(formula = aussies ~ guinearice)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.9448 -1.8917 -0.3272  1.8620 10.4210 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -7.493      1.203  -6.229 2.25e-07 ***
## guinearice    40.288      1.337  30.135  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.239 on 40 degrees of freedom
## Multiple R-squared:  0.9578,	Adjusted R-squared:  0.9568 
## F-statistic: 908.1 on 1 and 40 DF,  p-value: &lt; 2.2e-16
```

---
# Regresión espuria

&lt;img src="presentacion_files/figure-html/tslm_mult2-1.png" width="300px" height="300px" style="display: block; margin: auto;" /&gt;

```
## 
## 	Breusch-Godfrey test for serial correlation of order up to 8
## 
## data:  Residuals from Linear regression model
## LM test = 28.813, df = 8, p-value = 0.000342
```

---
# Modelos de tendencia

- Como las variables independiente son asumidas como fijas, se puede utilizar el tiempo como una variable independiente.

- Los modelos más frecuentes:
  - **Tendencia lineal**:
  `$$Y_t=\beta_0+\beta_1 t + \epsilon_t$$`
  - **Tendencia cuadrática**:
  `$$Y_t=\beta_0+\beta_1 t +\beta_2 t^2 + \epsilon_t$$`

- Regresión no lineal.
  - Por ejemplo: LOESS.

---
# Modelos de tendencia

Vamos a ajustar un modelo de tendencia cuadrática a la serie de graduados de ITCR de 1975 a 2002:
  `$$Y_t=\beta_0+\beta_1 t +\beta_2 t^2 + \epsilon_t, t=1,...,T$$`

&lt;img src="presentacion_files/figure-html/unnamed-chunk-9-1.png" width="45%" style="display: block; margin: auto;" /&gt;


---

# Modelos de tendencia



```r
tiempo&lt;-seq(1,length(y))
tiempo2&lt;-tiempo^2
mod&lt;-lm(y~tiempo+tiempo2)
summary(mod)
```

```

Call:
lm(formula = y ~ tiempo + tiempo2)

Residuals:
     Min       1Q   Median       3Q      Max 
-117.932  -49.683    4.506   43.234  155.390 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 127.0021    43.6818   2.907  0.00753 ** 
tiempo      -12.7887     6.9427  -1.842  0.07736 .  
tiempo2       1.5612     0.2323   6.720 4.83e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 71.61 on 25 degrees of freedom
Multiple R-squared:  0.944,	Adjusted R-squared:  0.9395 
F-statistic: 210.6 on 2 and 25 DF,  p-value: 2.268e-16
```


---
# Modelos de tendencia

.pull-left[
&lt;img src="presentacion_files/figure-html/unnamed-chunk-11-1.png" width="100%" /&gt;
]

.pull-right[
&lt;img src="presentacion_files/figure-html/unnamed-chunk-12-1.png" width="100%" /&gt;
]

---
# Modelos de tendencia

- Supuestos:
  - Normalidad
  - Homoscedasticidad
  - Autocorrelación en el tiempo

&lt;img src="presentacion_files/figure-html/unnamed-chunk-13-1.png" width="35%" style="display: block; margin: auto;" /&gt;


---
# Modelos de tendencia

**Prueba de Durbin-Watson:**
Dado un modelo de regresión ajustado, suponga que el tipo de autocorrelación entre los errores tiene orden 1, i.e.
`$$\epsilon_t= \rho \epsilon_{t-1}+a_t$$`
donde `\(\rho\)` es la correlación de un rezago y `\(a_t \sim N(0,\sigma^2)\)`

Defina las hipótesis:&lt;br /&gt; 
`\(H_0: \rho=0\)`  &lt;br /&gt; 
`\(H_1: \rho \neq 0\)` &lt;br /&gt; 



```r
durbinWatsonTest(mod)
```

```
 lag Autocorrelation D-W Statistic p-value
   1       0.1488158      1.576164   0.106
 Alternative hypothesis: rho != 0
```

---
# Modelos de tendencia


&lt;img src="presentacion_files/figure-html/unnamed-chunk-15-1.png" width="50%" style="display: block; margin: auto;" /&gt;

```
## 
## 	Breusch-Godfrey test for serial correlation of order up to 6
## 
## data:  Residuals
## LM test = 3.9215, df = 6, p-value = 0.6873
```


---
# Transformaciones en modelos estacionales

- Si la magnitud del cambio estacional se mantiene aproximadamente constante con el cambio del nivel de la serie, se dice que la variación estacional es constante (aditiva).
- Si la variación estacional aumenta proporcionalmente con el nivel de la serie, se dice que la variación estacional es multiplicativa.

Transformaciones usadas en la práctica:

- `\(W_t=Y_t^\alpha,~~\text{con} -1&lt;\alpha&lt;1\)`

- `\(W_t=\ln Y_t\)`

---
# Transformaciones en modelos estacionales

**Ejemplo de turistas:**


.pull-left[
Sin transformación `\((Y_t)\)`

&lt;img src="presentacion_files/figure-html/unnamed-chunk-16-1.png" width="70%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

Con transformación `\((\ln Y_t)\)`


&lt;img src="presentacion_files/figure-html/unnamed-chunk-17-1.png" width="70%" style="display: block; margin: auto;" /&gt;

]

---
# Modelos de series estacionales mediante variables indicadoras

- La idea es utilizar un factor (variables indicadoras) como predictor para indicar el periodo de la estacionalidad.
- Ejemplo de turistas (datos mensuales y con tendencia cuadrática)

`$$ln Y_t=\alpha_0+\alpha_1 t + \alpha_2 t^2 +\beta_1 I_{1}+...+\beta_11 I_{11}+\epsilon_t$$` 


```
            Estimate Std. Error  t value Pr(&gt;|t|)
(Intercept)  10.9420     0.0294 372.1819   0.0000
tiempo        0.0086     0.0008  11.1807   0.0000
tiempo2       0.0000     0.0000  -3.2291   0.0017
mes2         -0.1013     0.0324  -3.1246   0.0023
mes3         -0.1181     0.0324  -3.6408   0.0004
mes4         -0.3467     0.0324 -10.6900   0.0000
mes5         -0.5050     0.0324 -15.5680   0.0000
mes6         -0.4243     0.0324 -13.0771   0.0000
mes7         -0.2037     0.0325  -6.2784   0.0000
mes8         -0.3326     0.0325 -10.2482   0.0000
mes9         -0.6091     0.0325 -18.7601   0.0000
mes10        -0.5293     0.0325 -16.2990   0.0000
mes11        -0.3263     0.0325 -10.0431   0.0000
mes12        -0.1042     0.0325  -3.2068   0.0018
```

---
# Modelos de series estacionales mediante variables indicadoras

&lt;img src="presentacion_files/figure-html/unnamed-chunk-19-1.png" width="50%" style="display: block; margin: auto;" /&gt;






    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
